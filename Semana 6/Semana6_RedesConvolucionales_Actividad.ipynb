{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    "\n",
    "\n",
    "# Redes convolucionales\n",
    "\n",
    "\n",
    "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    "\n",
    "En este cuadernos estudiaremos las redes profundas convolucionales (CNN). Implementaremos nuestra propia red utilizando la biblioteca (API) Keras (https://keras.io/). \n",
    "\n",
    "Probaremos nuestros modelos más complejos de *deep learning* para la detección automática de frailejones sobre imagenes aereas del páramo e intentaremos mejorar los resultados que obtuvimos con nuestras redes más sencillas. Recordemos que hasta ahora hemos logrado unos resultados preliminares con un *accuracy* de validación de 0.86, utilizando una red sencilla de 5 neuronas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importemos algunos de los paquetes que vamos a utilizar:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ImportImagenesRGB import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = import_imagenes_RGB()\n",
    "\n",
    "print(X.shape, Y.shape, X[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "\n",
    "(250, 70, 70, 3) (1, 250) [0.58823529 0.5372549  0.40392157]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Redes convolucionales\n",
    "\n",
    "Las redes convolucionales (CNN: *Convolutional Neural Nets*) es un tipo de red neuronal (profunda) que suele usarse para el tratamiento de imagenes y la vision computacional, pero que también sirve para otras tareas como el procesamiento de datos secuenciales, lenguage natural, datos geo-referenciados o datos estructurados que guarden ciertas correlaciones entre sí (ver por ejemplo W. Kim (2014) Convolutional Neural Networks for Sentence Classification). \n",
    "\n",
    "Se les concoce por ser invariantes a translaciones, de tal manera que con su arquitectura producen exactamente la misma respuesta ante diferentes traslaciones (como por ejemplo rotaciones) que se le aplique a los datos de entrada. \n",
    "\n",
    "Un aspecto importante para entender las CNN de la mano con el tema que hemos visto hasta ahora en el curso, consiste en entender que los pesos y sesgos de una *capa convolucional* son **filtros** que extraen patrones particulares de los datos de entrada. Luego de la extracción de patrones, la red cuenta con capas densamente conectadas donde distintas neuronas pueden compartir el mismo filtro. \n",
    "\n",
    "Veamos:\n",
    "https://medium.com/analytics-vidhya/deep-learning-methods-1700548a3093\n",
    "\n",
    "Entonces, las CNN se pueden entender como versiones regularizadas de las redes multi-capa *densamente conectadas* (donde cada neurona en una capa está conectada con todas las demás neuronas de la siguiente capa). Este tipo de conexión *densa* facilita el *sobre-ajuste* a los datos de muestra con los que se construyen los mdoelos. Así, las CNN se enfocan en construir patrones más complejos pero más simples, encontrando *areas* de atención en las que enfocarse, haciendo uso de filtros y de **convoluciones** (formalmente hablando, una convolución corresponde con la operación matemática de la correlación cruzada). \n",
    "\n",
    "Veamos un ejemplo con un filtro de $3\\times 3$ y una *stride* de 1:\n",
    "\n",
    "\n",
    "$$ Imagen = \\begin{bmatrix}\n",
    "    1  & 1  & 1 & 0 & 0\\\\\n",
    "    0 & 1 & 1 & 1 & 0 \\\\\n",
    "    0  & 0 & 1  & 1 & 1 \\\\\n",
    "    0 & 0 & 1 & 1 & 0 \\\\\n",
    "    0  & 1 & 1  & 0 & 0\n",
    "\\end{bmatrix};\\;\\;\\; Filtro = \\begin{bmatrix}\n",
    "    1  & 0  & 1\\\\\n",
    "    0  & 1 & 0 \\\\\n",
    "    1  & 0 & 1 \n",
    "\\end{bmatrix}; \\;\\;\\; Patron =\\begin{bmatrix}\n",
    "    4  & 3  & 4\\\\\n",
    "    2  & 4 & 3 \\\\\n",
    "    2  & 3 & 4 \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Para obtener el nuevo patrón convolucionado, resolvemos la operación $\\otimes_1$ denotando una convolución con un *stride* de 1, o una *ventana móvil de 1 en 1*, tal que $Patron = Imagen \\otimes_1 Filtro$.\n",
    "\n",
    "\n",
    "\n",
    "Además de la operación convolucional, tras una capa convolucional le suele seguir un filtro de agregación conocido como **pooling**. Este filtro también toma ventanas móviles y resume los valores dentro de su rango de acuerdo con una operación de agregación específica.\n",
    "\n",
    "Por ejmplo, un *Max-pooling* consiste en tomar el máximo dentro de cada ventana. Si tomamos un filtro de Max-pooling de tamaño $2\\times 2$ y un *stride* de 2, y lo aplicamos sbre el patrón $P$, obtenemos:\n",
    "\n",
    "$$ P = \\begin{bmatrix}\n",
    "    5  & 4  & 6 & 3\\\\\n",
    "    3  & 9 & 4 & 5 \\\\\n",
    "    8  & 1 & 7  & 9  \\\\\n",
    "    0 & 2 & 8 & 0  \n",
    "\\end{bmatrix}\\;\\;\\; $$\n",
    "\n",
    "$$ MaxPool_{2\\times 2}^{stride=2}(P) = \\begin{bmatrix}\n",
    "    9  & 6\\\\\n",
    "    8  & 9\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "La gran ventaja de las CNN es que aprenden de manera automática (sin necesidad de conocimiento previo) los filtros que de otro modo habría que especificar explícita o manualmente. \n",
    "\n",
    "Especifiquemos a continuación la arquitectura de nuestra CNN, donde vamos a hacer uso de una técnica de **Drop-out** antes de la capa de salida. Esta técnica elimina aleatoriamente y de manera temporal (en cada iteración) un número de neuronas determinado (por una tasa de eliminación o *drop-out*), con el fin de que el modelo no recaiga demasidado en ciertas neuronas y generalize de la mejor manera la función a estimar :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicializacion Normal\n",
    "initnorm = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)\n",
    "\n",
    "# Inicializacion de He\n",
    "initHe = keras.initializers.he_normal(seed=1)\n",
    "\n",
    "# Arquitectura de la red\n",
    "model = Sequential()  \n",
    "model.add(Conv2D(32, (3, 3), input_shape=X.shape[1:], activation='tanh', kernel_initializer=initnorm, bias_initializer='zeros'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(32, (3, 3), activation='tanh', kernel_initializer=initnorm, bias_initializer='zeros'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='selu', kernel_initializer=initHe, bias_initializer='zeros'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_initializer=initHe, bias_initializer='zeros'))\n",
    "model.add(Dropout(rate=0.2, seed=1))   \n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer=initnorm, bias_initializer='zeros')) \n",
    "    \n",
    "# Guardamos la arquitectura de red\n",
    "config_cnn = model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador de Adam\n",
    "\n",
    "Vamos a implementar la red convolucional con la arquitectura especificada arriba haciendo uso del método de optimización estocástica de **Adam** (Kingma & Ba (2015)). El término *Adam* se debe a *Adaptive Moment Estimation*, y se puede entender como una revisión al método de RMSProp. Bajo Adam, se utilizan promedios móviles tanto de los gradientes como de sus segundos momentos.  De esta manera, se tiene que \n",
    "\n",
    "$$ u(\\theta) = \\rho_1 u(\\theta_{viejo}) + (1-\\rho_1) \\frac{\\partial J (\\hat \\theta_{viejo}; x^{(i)}, y^{(i)})}{ \\partial \\hat \\theta_{viejo} }  $$\n",
    "\n",
    "$$ v(\\theta) = \\rho_2 v(\\theta_{viejo}) + (1-\\rho_2) \\biggr( \\frac{\\partial J (\\hat \\theta_{viejo}; x^{(i)}, y^{(i)})}{ \\partial \\hat \\theta_{viejo} } \\biggl)^2  $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ \\hat u = \\frac{u(\\theta)}{1-\\rho_1^t} $$\n",
    "\n",
    "$$ \\hat v = \\frac{v(\\theta)}{1-\\rho_2^t} $$\n",
    "\n",
    "De tal manera que la actualización de los parámetros se lleva a cabo mediante:\n",
    "\n",
    "$$ \\hat \\theta_{nuevo} = \\hat \\theta_{viejo} - \\alpha \\frac{\\hat u}{\\sqrt{\\hat v}+\\varepsilon}$$ \n",
    "\n",
    "donde $\\varepsilon$ es un escalar muy pequeño (infinitesimal) que previene la división por cero, $\\rho_1, \\rho_2$ son respectivamente  los factores de memoria sobre el primer y segundo momento de los gradientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inicializamos la tabla donde guardamos los resultados\n",
    "x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\", \"Epoca\"])\n",
    "\n",
    "# Definimos el número máximo de iteraciones (épocas de la red)\n",
    "epocas=100\n",
    "\n",
    "# Definimos los parametros del Adam\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "\n",
    "# implementamos 3 repeticiones con particiones distintas de entrenamiento y doble validacion\n",
    "for i in range(0,3,1):\n",
    "    r = i^3\n",
    "    CE_x, CV0_x, CE_y, CV0_y = train_test_split(X, Y.T, test_size = 0.3, random_state = r)\n",
    "    CV_x, CP_x, CV_y, CP_y = train_test_split(CV0_x, CV0_y, test_size = 0.5, random_state = r)\n",
    "       \n",
    "    # Definimos la arquitectura de la red\n",
    "    model = Sequential.from_config(config_cnn)\n",
    "    \n",
    "    # Definimos el método de optimización con respecto a su funcion de perdida (además guardamos la exactitud para cada iteracion)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    # Ajustamos el modelo\n",
    "    history=model.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=0, shuffle=False)\n",
    "    \n",
    "    # Encontramos el mejor modelo en validación\n",
    "    min_err=np.min(history.history['val_loss'])\n",
    "    best_epoc=np.where(history.history['val_loss'] == min_err)[0] \n",
    "       \n",
    "    # Conseguimos el mejor modelo de acuerdo con su desempeño en validación\n",
    "    model.fit(x=CE_x, y=CE_y, epochs=best_epoc[0], validation_data=(CV_x, CV_y), verbose=0, shuffle=False)\n",
    "            \n",
    "    # Calculamos las metricas\n",
    "    train_metrics = model.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "    valid_metrics = model.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "    test_metrics = model.evaluate(x=CP_x, y=CP_y, verbose=0)\n",
    "    \n",
    "    ## Guardamos las métricas de desempeño\n",
    "    accu_e = train_metrics[1]\n",
    "    loss_e = train_metrics[0]\n",
    "    accu_v = valid_metrics[1]\n",
    "    loss_v = valid_metrics[0]\n",
    "    accu_p = test_metrics[1]\n",
    "    loss_p = test_metrics[0]\n",
    "    \n",
    "    if (loss_p < err_p):\n",
    "        pathr =('modelo_CNN_initseed=1_part_seed='+str(r)+'.h5')\n",
    "        model.save(pathr) \n",
    "        err_p = loss_p\n",
    "\n",
    "    # Imprimimos el desempeño para cada repetición\n",
    "    print('Epoca= '+str(best_epoc[0])+' , accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "    \n",
    "    x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4), best_epoc[0]])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3.1\n",
    "\n",
    "Qué puede observar sobre estos resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos el aprendizaje del mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('Exactitud')  \n",
    "plt.ylabel('Acc')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validacion'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1) \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Pérdida')  \n",
    "plt.ylabel('Pérdida')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validación'], loc='upper right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el mejor modelo y confirmamos el desempeño del modelo sobre todo el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# red convolucional\n",
    "model_3 = load_model('modelo_CNN_initseed=1_part_seed=3.h5')\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el desempeño del mejor modelo sobre todo el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model_3.predict(X)\n",
    "Y_preds = (Y_pred > 0.5)\n",
    "\n",
    "confusion_matrix(Y.T, Y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "    \n",
    "<table style=\"width:20%\">\n",
    "    <tr>\n",
    "       <td> 134 </td>\n",
    "       <td> 11 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> 4 </td>\n",
    "       <td> 101 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.1\n",
    "\n",
    "Intente hacer que el optimizador Adam converja en todas las repeticiones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.2\n",
    "\n",
    "Compare los resultados al utilizar otros algoritmos de aprendizaje como RMSprop o el mismo SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.3\n",
    "\n",
    "Compare los resultados con distintas tasas de *drop-out*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bono\n",
    "\n",
    "Visualice los distintos filtros convolucionales para entender qué tipo de patrones están aprendiendo que son relevantes para la detección de frailejones.\n",
    "\n",
    "*A continuación se indica cómo visulizar una capa convolucional. Examine las distintas capas convolucionales y analice lo que puede visualizar.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargamos los pesos de la primera capa escondida\n",
    "filters, biases = model_3.layers[0].get_weights()\n",
    "# normalizamos los valores de los filtros (0,1)\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "# graficamos los primeros filtros\n",
    "n_filters, ix = 6, 1\n",
    "for i in range(n_filters):\n",
    "# tomamos los filtros\n",
    "    f = filters[:, :, :, i]\n",
    "# graficamos cada canal separadamente\n",
    "    for j in range(3):\n",
    "        # subplot y axis\n",
    "        ax = pyplot.subplot(n_filters, 3, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "# graficamos cada filtro en escala de grises\n",
    "        pyplot.imshow(f[:, :, j], cmap='gray')\n",
    "        ix += 1\n",
    "# graficamos la figura\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Caso aplicado\n",
    "\n",
    "Ahora probemos nuestro modelo sobre la imagen completa de prueba del paramo ``IMG_3451.JPG``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import image\n",
    "\n",
    "img = image.load_img('IMG_3451.JPG')\n",
    "img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo pasamos por nuestra imagen de prueba\n",
    "x = np.array(img)\n",
    "x2 = x\n",
    "\n",
    "ni = x.shape[0]-50\n",
    "mi = x.shape[1]-50\n",
    "\n",
    "f1=0\n",
    "f2=70\n",
    "for i in range(1,ni,50):\n",
    "    c1=0\n",
    "    c2=70\n",
    "    for j in range(1,mi,50):\n",
    "        subi=x[f1:f2,c1:c2,]/255.\n",
    "        subi2=np.expand_dims(subi,0)\n",
    "        Y_preds = model_3.predict(subi2)\n",
    "        pred_P = (Y_preds > 0.5)\n",
    "        if(pred_P==1):\n",
    "            x2[f1:f2,c1:c2,2]=0\n",
    "        c1=c1+50\n",
    "        c2=c2+50\n",
    "    f1=f1+50\n",
    "    f2=f2+50\n",
    "        \n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lectura avanzada sobre métodos de optimización en redes profundas: https://openreview.net/pdf?id=ryQu7f-RZ\n",
    "http://www.cs.utoronto.ca/~ilya/pubs/2013/1051_2.pdf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "c4HO0",
   "launcher_item_id": "lSYZM"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

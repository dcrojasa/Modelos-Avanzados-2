{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    "\n",
    "\n",
    "# Red neuronal recurrente: LSTM bidireccional\n",
    "\n",
    "## Actividad 8\n",
    "\n",
    "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    "\n",
    "## Actividad en grupos\n",
    "### Nombres:\n",
    "\n",
    "**Instrucciones:** Por favor escriba los nombres de los integrantes de su grupo. Esta actividad debe ser entregada a más tardar dentro de 8 días, con la respuesta para los ejercicios y preguntas en cada numeral.\n",
    "\n",
    "En este cuaderno vamos a implementar una red recurrente bi-direccional para la prediccion del sentimiento asociado con un comentario linguistico. Los comentarios con los que vamos a trabajar corresponden con opiniones sobre peliculas (https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "Finalmente tenemos un ejercicio donde podremos explorar distintos modelos de redes recurrentes (https://en.wikipedia.org/wiki/Recurrent_neural_network)\n",
    "\n",
    "Primero importemos las bibliotecas y paquetes que vamos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import load_model, Sequential\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También definimos algunos parámetros para nuestra implementación, uno donde definimos el número máximo de términos a considerar (de todo nuestro vocabulario) y otro donde definimos la longitud máxima para un comentario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000  # Considera las 20000 palabras más populares\n",
    "maxlen = 200  # Considera las primeras 200 palabras de cada comentario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importemos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(\n",
    "    num_words=max_features)\n",
    "\n",
    "print(len(x_train), \"secuencias de entrenamiento\")\n",
    "print(len(x_val), \"secuencias de validación\")\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "\n",
    "25000 secuencias de entrenamiento\n",
    "\n",
    "25000 secuencias de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos en qué consiste la priemra observación de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reconstruir cada comentario de acuerdo con el índice de cada término:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = keras.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")\n",
    "\n",
    "L = {k:(v+3) for k,v in L.items()}\n",
    "L[\"<PAD>\"] = 0\n",
    "L[\"<START>\"] = 1\n",
    "L[\"<UNK>\"] = 2\n",
    "L[\"<UNUSED>\"] = 3\n",
    "\n",
    "L_palabra = {value:key for key,value in L.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el primer comentario de entrenamiento que es positivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El comentario: \", ' '.join(L_palabra[id] for id in x_train[0] ))\n",
    "print(\"Tiene un sentimiento asociado: \", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O un comentario negativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El comentario: \", ' '.join(L_palabra[id] for id in x_train[1] ))\n",
    "print(\"Tiene un sentimiento asociado: \", y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Red recurrente bi-direccional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definimos la arquitectura de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input con secuencias de enteros con longitud variable\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Conseguimos la representación vectorial (embedding) de cada entero en un vector 128-dimensional\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "\n",
    "# Añadimos 2 unidades LSTM bidireccionales\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "# Añadimos un clasificador binario en la salida\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Gaurdamos la arquitectura del modelo\n",
    "model1 = keras.Model(inputs, outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos la tabla donde guardamos los resultados\n",
    "x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\"])\n",
    "\n",
    "# Definimos el número máximo de iteraciones (épocas de la red)\n",
    "epocas=3\n",
    "\n",
    "# Definimos los parametros del Adam\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "\n",
    "for i in range(0,3,1):\n",
    "    r = i^3\n",
    "    CE_x, CV_x, CE_y, CV_y = train_test_split(x_train, y_train, test_size = 0.5, random_state = r)\n",
    "          \n",
    "    # Definimos el método de optimización con respecto a su funcion de perdida (además guardamos la exactitud para cada iteracion)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    # Ajustamos el modelo\n",
    "    history=model.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=1, shuffle=False)\n",
    "      \n",
    "    # Calculamos las metricas\n",
    "    train_metrics = model.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "    valid_metrics = model.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "    test_metrics = model.evaluate(x=x_val, y=y_val, verbose=0)\n",
    "    \n",
    "    # Guardamos las métricas de desempeño\n",
    "    accu_e = train_metrics[1]\n",
    "    loss_e = train_metrics[0]\n",
    "    accu_v = valid_metrics[1]\n",
    "    loss_v = valid_metrics[0]\n",
    "    accu_p = test_metrics[1]\n",
    "    loss_p = test_metrics[0]\n",
    "    \n",
    "    if (loss_p < err_p):\n",
    "        pathr =('BRNN_part='+str(r)+'.h5')\n",
    "        model.save(pathr) \n",
    "        err_p = loss_p\n",
    "    \n",
    "    # Imprimimos el desempeño para cada repetición\n",
    "    print('Desempeño (exactitud): accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "    \n",
    "    x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4)])\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('Exactitud')  \n",
    "plt.ylabel('Acc')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validacion'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1) \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Pérdida')  \n",
    "plt.ylabel('Pérdida')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validación'], loc='upper right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperamos el mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B-RNN LSTM\n",
    "model_brnn = load_model('BRNN_part=3.h5')\n",
    "\n",
    "model_brnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicamos los resultados obtenidos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predt = model_brnn.predict(x_train)\n",
    "Y_predst = (Y_predt > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_train, Y_predst))\n",
    "print(\"Exactitud: \", model_brnn.evaluate(x=x_train, y=y_train, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reportamos el desempeño del modelo con los datos de prueba (fuera de la muestra):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10290  2210]\n",
      " [ 2003 10497]]\n",
      "Exactitud:  0.8314800262451172\n"
     ]
    }
   ],
   "source": [
    "Y_predv = model_brnn.predict(x_val)\n",
    "Y_predsv = (Y_predv > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_val, Y_predsv))\n",
    "print(\"Exactitud: \", model_brnn.evaluate(x=x_val, y=y_val, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.1\n",
    "\n",
    "Desarrolle un modelo de red neuronal recurrente uni-direccional para comparar los resultados obtenidos con esta red recurrente bi-direccional.\n",
    "\n",
    "Puede explorar una red recurrente simple, LSTM ó GRU, o cualquier otro tipo de red que desee explorar que contenga al menos una capa de tipo recurrente (ver por ejemplo: https://keras.io/api/layers/#recurrent-layers).\n",
    "\n",
    "Compare los resultados sobre los datos de prueba y analice el desempeño de su modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.2\n",
    "\n",
    "Desarrolle otro modelo de red neuronal (de libre elección) para mejorar los resultados obtenidos con el mejor modelo obtenido hasta ahora.\n",
    "\n",
    "Puede explorar una red recurrente simple, LSTM, GRU, o cualquier otro tipo de red (CNN, CNN-LSTM, ...)\n",
    "\n",
    "Compare los resultados sobre los datos de prueba y analice el desempeño de su modelo. Concluya y proponga estrategias para seguir mejorando los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "wRuwL",
   "launcher_item_id": "NI888"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
